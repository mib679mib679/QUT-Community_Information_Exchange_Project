{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2955295-0a3d-4f1e-8038-5c010c10bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, 'display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8404dd29-097f-4500-8d97-24f1da924a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55185 entries, 0 to 55184\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   PartitionKey     55185 non-null  int64  \n",
      " 1   UserHostAddress  55185 non-null  object \n",
      " 2   WhatText         55185 non-null  object \n",
      " 3   CategoryID       39621 non-null  float64\n",
      " 4   Postcode         55185 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"202001_preprocessed.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62f4191a-d59a-4a0d-9e8e-945c97febda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "#storing the puntuation free text\n",
    "\n",
    "df['WhatText'] = df['WhatText'].str.replace(\"/\", \" \")\n",
    "df['WhatText'] = df['WhatText'].str.replace(\"_\", \" \")\n",
    "df['no_punc']= df['WhatText'].apply(lambda x:remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5668a382-90ca-42e2-887b-53a9eeda1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word tokenization\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "df['tokenized_sents'] = df.apply(lambda row: nltk.word_tokenize(row['no_punc']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c898ac12-4f0f-405d-8fa4-4959715dd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "#defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text):\n",
    "    output = [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "#applying the function\n",
    "df['no_stopwords']= df['tokenized_sents'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a46bab35-3813-4a9f-8b6d-509c27dd0b2e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "# create N-grams\n",
    "def make_n_grams(texts):\n",
    "    bigram = gensim.models.Phrases(texts, min_count = 1, threshold=1)  # higher threshold fewer phrases.\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    \n",
    "    trigram = gensim.models.Phrases(bigram[texts], threshold=1)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    \n",
    "    bigrams_text = [bigram_mod[doc] for doc in texts]\n",
    "    trigrams_text =  [trigram_mod[bigram_mod[doc]] for doc in bigrams_text]\n",
    "    return trigrams_text\n",
    "\n",
    "tokens_reviews = make_n_grams(df[\"no_stopwords\"])\n",
    "df['n_gram'] = tokens_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3dd47cc0-add3-4e9e-9bb2-72b9d43684e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "df['text_ready'] = df['n_gram'].apply(lambda x:lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b641adc-6084-42de-87cd-9a210030e4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 53516 clusters with 122 clusters populated\n",
      "In stage 1: transferred 46922 clusters with 122 clusters populated\n",
      "In stage 2: transferred 41425 clusters with 122 clusters populated\n",
      "In stage 3: transferred 38643 clusters with 122 clusters populated\n",
      "In stage 4: transferred 36264 clusters with 122 clusters populated\n",
      "In stage 5: transferred 33352 clusters with 122 clusters populated\n",
      "In stage 6: transferred 30850 clusters with 122 clusters populated\n",
      "In stage 7: transferred 29162 clusters with 122 clusters populated\n",
      "In stage 8: transferred 27750 clusters with 122 clusters populated\n",
      "In stage 9: transferred 26492 clusters with 122 clusters populated\n",
      "In stage 10: transferred 25547 clusters with 122 clusters populated\n",
      "In stage 11: transferred 24823 clusters with 122 clusters populated\n",
      "In stage 12: transferred 23902 clusters with 122 clusters populated\n",
      "In stage 13: transferred 23265 clusters with 122 clusters populated\n",
      "In stage 14: transferred 22712 clusters with 122 clusters populated\n",
      "In stage 15: transferred 22118 clusters with 122 clusters populated\n",
      "In stage 16: transferred 21557 clusters with 122 clusters populated\n",
      "In stage 17: transferred 20901 clusters with 122 clusters populated\n",
      "In stage 18: transferred 20283 clusters with 122 clusters populated\n",
      "In stage 19: transferred 19660 clusters with 122 clusters populated\n",
      "In stage 20: transferred 19057 clusters with 122 clusters populated\n",
      "In stage 21: transferred 18698 clusters with 122 clusters populated\n",
      "In stage 22: transferred 18392 clusters with 122 clusters populated\n",
      "In stage 23: transferred 18299 clusters with 122 clusters populated\n",
      "In stage 24: transferred 17890 clusters with 122 clusters populated\n",
      "In stage 25: transferred 17500 clusters with 122 clusters populated\n",
      "In stage 26: transferred 17289 clusters with 122 clusters populated\n",
      "In stage 27: transferred 17021 clusters with 122 clusters populated\n",
      "In stage 28: transferred 16560 clusters with 122 clusters populated\n",
      "In stage 29: transferred 16243 clusters with 122 clusters populated\n",
      "In stage 30: transferred 16048 clusters with 122 clusters populated\n",
      "In stage 31: transferred 15586 clusters with 122 clusters populated\n",
      "In stage 32: transferred 15274 clusters with 122 clusters populated\n",
      "In stage 33: transferred 15173 clusters with 122 clusters populated\n",
      "In stage 34: transferred 15099 clusters with 122 clusters populated\n",
      "In stage 35: transferred 14717 clusters with 122 clusters populated\n",
      "In stage 36: transferred 14161 clusters with 122 clusters populated\n",
      "In stage 37: transferred 13835 clusters with 122 clusters populated\n",
      "In stage 38: transferred 13723 clusters with 122 clusters populated\n",
      "In stage 39: transferred 13672 clusters with 122 clusters populated\n"
     ]
    }
   ],
   "source": [
    "from gsdmm import MovieGroupProcess\n",
    "#pip install git+https://github.com/rwalk/gsdmm.git\n",
    "\n",
    "# Gibbs Samping Dirichlet Multinomial Mixture Model (GSDMM) in Short-Text Clustering\n",
    "mgp = MovieGroupProcess(K = 122, alpha=0.01, beta=0.01, n_iters=40)\n",
    "vocab = set(x for text in df[\"text_ready\"] for x in text)\n",
    "n_terms = len(vocab)\n",
    "model = mgp.fit(df[\"text_ready\"], n_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f686f666-921d-4291-80dc-cd0253c761a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [  89   89   57  220   77  132  108   81   50   55   50   52  194  109\n",
      "  752   43   55 1872  300   86   57   80  197   27   96   75  491  800\n",
      "  998   49 9806  241   32  117  195  245 1319   85   86 2376 1961   85\n",
      "   88   71  126  132  128  234   88   68   23 1911 1576  123   68  487\n",
      "  114  103  113   65   39   75  805  222   15   87   78  116   65   77\n",
      "   91   64   39  196  106  109   48   56   73 3307  147   68   34   93\n",
      "  206 7274 2039  591   54   84  159  105   79   75   53   89   77  107\n",
      "   46  122 4058  112   47   57   96  161  217   63   92  367  149   74\n",
      "   47  111 1315   53   85   71  293  765  138  237]\n",
      "\n",
      "Most important clusters (by number of docs inside): [ 30  85 100  79  39  86  40  51  17  52]\n",
      "\n",
      "Cluster 30 : [('others', 1276), ('seniors_clubs_social_groups', 739), ('state_primary_high_schools', 701), ('event', 696), ('crisis_emergency_accommodation', 690), ('community_clubs_interest_groups', 667), ('sports_clubs', 640), ('drug_alcohol_services', 600), ('general_community_clubs', 484), ('outdoor_sport', 481)]\n",
      "\n",
      "Cluster 85 : [('others', 2201), ('general_practice_doctor', 1174), ('sports_clubs', 496), ('welfare_assistance_services', 480), ('child_protection_services', 392), ('general_community_facilities', 353), ('general_education_programs', 341), ('food_vans_kitchens', 330), ('state_primary_high_schools', 292), ('fitness_activities', 287)]\n",
      "\n",
      "Cluster 100 : [('service', 3992), ('general', 3281), ('accommodation', 2092), ('disability', 1399), ('youth', 631), ('ageing', 367), ('crisis_emergency_accommodation', 7), ('specialist_homelessness_services', 7), ('doomadgee_hospital', 3), ('mount_gravatt', 2)]\n",
      "\n",
      "Cluster 79 : [('child_protection_services', 642), ('crisis_emergency_accommodation', 551), ('general_community_clubs', 423), ('community_halls', 348), ('others', 292), ('children_youth_clubs', 175), ('general_education_programs', 173), ('youth_information_counselling', 128), ('state_primary_high_schools', 100), ('general_community_facilities', 76)]\n",
      "\n",
      "Cluster 39 : [('service', 2168), ('general', 1871), ('health', 1172), ('volunteering', 463), ('aboriginal', 430), ('ageing', 257), ('transport', 90), ('advocacy', 34), ('accommodation', 9), ('clinic_87_hiv_sexual', 6)]\n",
      "\n",
      "Cluster 86 : [('general', 2019), ('welfare_support_services', 1032), ('communication_information', 652), ('recreation_leisure', 338), ('cairns_base_hospital', 5), ('deadly_ears', 3), ('program_children', 3), ('health_qhhs', 3), ('self_help', 2), ('welfare_assistance_services', 2)]\n",
      "\n",
      "Cluster 40 : [('play_groups_childcare', 1014), ('general_cultural_groups', 183), ('general_practice_doctor', 163), ('meals_wheels', 90), ('state_primary_high_schools', 75), ('event', 55), ('crisis_emergency_services', 46), ('child_protection_services', 40), ('cultural_migrant_services', 39), ('others', 36)]\n",
      "\n",
      "Cluster 51 : [('service', 1874), ('mental_health', 684), ('general_employment_training', 299), ('general_crisis_emergency', 239), ('disability_employment_training', 237), ('welfare_assistance_support', 176), ('aged_care_accommodation', 109), ('hearing', 50), ('brisbane', 38), ('health_screening', 30)]\n",
      "\n",
      "Cluster 17 : [('churches_places_worship', 391), ('allied_health', 273), ('community_transport', 234), ('craft', 171), ('event', 134), ('child_protection_services', 111), ('mackay', 96), ('dental_oral_health', 70), ('specialist_outpatient_clinics', 68), ('indoor_sports', 42)]\n",
      "\n",
      "Cluster 52 : [('service', 1564), ('welfare_assistance_support', 755), ('migrant', 242), ('psychiatric', 221), ('general_crisis_emergency', 141), ('home_care_safety', 83), ('adult_health', 66), ('crisis_counselling_intervention', 32), ('youth_crisis_emergency', 14), ('oxley_disability', 9)]\n"
     ]
    }
   ],
   "source": [
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print(\"\\nCluster %s : %s\"%(cluster,sort_dicts))\n",
    "        \n",
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "\n",
    "# topics sorted by the number of document they are allocated to\n",
    "top_index = doc_count.argsort()[-10:][::-1]\n",
    "print('\\nMost important clusters (by number of docs inside):', top_index)\n",
    "# show the top 5 words in term frequency for each cluster \n",
    "top_words(mgp.cluster_word_distribution, top_index, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "511943e3-d44c-4f0a-bd5b-af47e2162f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PartitionKey</th>\n",
       "      <th>UserHostAddress</th>\n",
       "      <th>WhatText</th>\n",
       "      <th>CategoryID</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>n_gram</th>\n",
       "      <th>text_ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200101</td>\n",
       "      <td>2001:8004:13c1:ba59:2917:4cd9:5ca3:a5f1</td>\n",
       "      <td>general health services</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4215</td>\n",
       "      <td>general health services</td>\n",
       "      <td>[general, health, services]</td>\n",
       "      <td>[general, health, services]</td>\n",
       "      <td>[general, health, services]</td>\n",
       "      <td>[general, health, service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200101</td>\n",
       "      <td>106.71.190.191</td>\n",
       "      <td>christmas fireworks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4020</td>\n",
       "      <td>christmas fireworks</td>\n",
       "      <td>[christmas, fireworks]</td>\n",
       "      <td>[christmas, fireworks]</td>\n",
       "      <td>[christmas_fireworks]</td>\n",
       "      <td>[christmas_fireworks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200101</td>\n",
       "      <td>122.148.129.117</td>\n",
       "      <td>general welfare &amp; support services</td>\n",
       "      <td>119.0</td>\n",
       "      <td>4215</td>\n",
       "      <td>general welfare  support services</td>\n",
       "      <td>[general, welfare, support, services]</td>\n",
       "      <td>[general, welfare, support, services]</td>\n",
       "      <td>[general, welfare_support_services]</td>\n",
       "      <td>[general, welfare_support_services]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200101</td>\n",
       "      <td>120.22.167.94</td>\n",
       "      <td>others</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000</td>\n",
       "      <td>others</td>\n",
       "      <td>[others]</td>\n",
       "      <td>[others]</td>\n",
       "      <td>[others]</td>\n",
       "      <td>[others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200101</td>\n",
       "      <td>2001:8004:1080:133e:386e:9184:a6ec:f67c</td>\n",
       "      <td>bunbury acute psychiatric unit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4215</td>\n",
       "      <td>bunbury acute psychiatric unit</td>\n",
       "      <td>[bunbury, acute, psychiatric, unit]</td>\n",
       "      <td>[bunbury, acute, psychiatric, unit]</td>\n",
       "      <td>[bunbury_acute_psychiatric_unit]</td>\n",
       "      <td>[bunbury_acute_psychiatric_unit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PartitionKey                          UserHostAddress  \\\n",
       "0      20200101  2001:8004:13c1:ba59:2917:4cd9:5ca3:a5f1   \n",
       "1      20200101                           106.71.190.191   \n",
       "2      20200101                          122.148.129.117   \n",
       "3      20200101                            120.22.167.94   \n",
       "4      20200101  2001:8004:1080:133e:386e:9184:a6ec:f67c   \n",
       "\n",
       "                             WhatText  CategoryID  Postcode  \\\n",
       "0             general health services        80.0      4215   \n",
       "1                 christmas fireworks         NaN      4020   \n",
       "2  general welfare & support services       119.0      4215   \n",
       "3                              others         NaN      4000   \n",
       "4      bunbury acute psychiatric unit         NaN      4215   \n",
       "\n",
       "                             no_punc                        tokenized_sents  \\\n",
       "0            general health services            [general, health, services]   \n",
       "1                christmas fireworks                 [christmas, fireworks]   \n",
       "2  general welfare  support services  [general, welfare, support, services]   \n",
       "3                             others                               [others]   \n",
       "4     bunbury acute psychiatric unit    [bunbury, acute, psychiatric, unit]   \n",
       "\n",
       "                            no_stopwords                               n_gram  \\\n",
       "0            [general, health, services]          [general, health, services]   \n",
       "1                 [christmas, fireworks]                [christmas_fireworks]   \n",
       "2  [general, welfare, support, services]  [general, welfare_support_services]   \n",
       "3                               [others]                             [others]   \n",
       "4    [bunbury, acute, psychiatric, unit]     [bunbury_acute_psychiatric_unit]   \n",
       "\n",
       "                            text_ready  \n",
       "0           [general, health, service]  \n",
       "1                [christmas_fireworks]  \n",
       "2  [general, welfare_support_services]  \n",
       "3                             [others]  \n",
       "4     [bunbury_acute_psychiatric_unit]  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706571d2-a292-4490-ae9c-731a679de4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34590, 5)\n"
     ]
    }
   ],
   "source": [
    "# Drop google bot IP\n",
    "df = df.drop(df[df.UserHostAddress.str.contains(\"66.249\")].index)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "735cadff-63e4-4826-ae52-a7ced7dad367",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4670' '4165' '4218' '4650' '4020' '4505' '4306' '4158' '4215' '4213'\n",
      " '4509' '4510' '4350' '4551' '4000' '4075' '4160' '4285' '4680' '4109'\n",
      " '4110' '4217' '4209' '4068' '4740' '4655' '4305' '4568' '4114' '4700'\n",
      " '4310' '4810' '4119' '4019' '4035' '4671' '4507' '4226' '4301' '4615'\n",
      " '4825' '4500' '4118' '4878' '4220' '4011' '4491' '4101' '4455' '4157'\n",
      " '4344' '4054' '4059' '4078' '4005' '4501' '4122' '4106' '4132' '4205'\n",
      " '4216' '4129' '4212' '4006' '4032' '4870' '4133' '4735' '4502' '4405'\n",
      " '4822' '4610' '4030' '4221' '4127' '4823' '4566' '4022' '4730' '4214'\n",
      " '4061' '4124' '4300' '4128' '4102' '4077' '4108' '4814' '4559' '4860'\n",
      " '4480' '4207' '4570' '4211' '4311' '4164' '4413' '4031' '4850' '4508'\n",
      " '4370' '4341' '4053' '4506' '4660' '4504' '4021' '4178' '4169' '4390'\n",
      " '4503' '4380' '4829' '4115' '4131' '4558' '4737' '4519' '4573' '4820'\n",
      " '4069' '4352' '4343' '4854' '4575' '4474' '4064' '4560' '4309' '4304'\n",
      " '4725' '4223' '4174' '4580' '4736' '4163' '4487' '4880' '4340' '4817'\n",
      " '4017' '4012' '4225' '4113' '4183' '4074' '4125' '4153' '4556' '4816'\n",
      " '4824' '4034' '4007' '4010' '4876' '4120' '4865' '4472' '4130' '4107'\n",
      " '4170' '4357' '4701' '4123' '4550' '4561' '4151' '4014' '4051' '4420'\n",
      " '4159' '4355' '4227' '4516' '4883' '4626' '4818' '4871' '4208' '4008'\n",
      " '4018' '4210' '4741' '4067' '4303' '4557' '4037' '4875' '4723' '4161'\n",
      " '4365' '4066' '4567' '4879' '4116' '4224' '4811' '4830' '4346' '4356'\n",
      " '4555' '4152' '4703' '4410' '4070' '4720' '4802' '4121' '4621' '4419'\n",
      " '4490' '4055' '4614' '4104' '4815' '4812' '4869' '4060' '4228' '4342'\n",
      " '4415' '4719' '4717' '4605' '4406' '4807' '4868' '4892' '4805' '4715'\n",
      " '4849' '4721' '4492' '4521' '4888' '4744' '4753' '4803' '4821' '4852'\n",
      " '4874' '4877' '4312' '4009' '4076' '4073' '4156' '4518' '4428' '4756'\n",
      " '4470' '4362' '4280' '4520' '4103' '4424' '4179' '4401' '4488' '4514'\n",
      " '4412' '4750' '4361' '4659' '4808' '4630' '4739' '4347' '4171' '4564'\n",
      " '4806' '4184' '4411' '4895' '4565' '4552' '4800' '4270' '4881' '4861'\n",
      " '4745' '4272' '4421' '4275' '4358' '4013' '4702' '4718' '4714' '4613'\n",
      " '4105' '4873' '4515' '4416' '4563' '4402' '4562' '4465' '4606' '4511'\n",
      " '4856' '4173' '4408' '4154' '4799' '4754' '4601' '4025' '4798' '4608'\n",
      " '4486' '4036' '4359' '4454' '4481' '4467' '4581' '4112' '4620' '4819'\n",
      " '4117' '4553' '4709' '4612' '4625' '4387' '4884' '4403' '4886' '4572'\n",
      " '4742' '4363' '4627' '4461']\n"
     ]
    }
   ],
   "source": [
    "df['Postcode'] = df['Postcode'].astype(\"str\")\n",
    "df = df[~df.Postcode.str.startswith('8')]\n",
    "df = df[~df.Postcode.str.startswith('7')]\n",
    "df = df[~df.Postcode.str.startswith('6')]\n",
    "df = df[~df.Postcode.str.startswith('5')]\n",
    "df = df[~df.Postcode.str.startswith('3')]\n",
    "df = df[~df.Postcode.str.startswith('2')]\n",
    "print(df[\"Postcode\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2901f-101d-40c7-84f8-24c8be389a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
